{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3')\n",
    "#USE_CNN_module = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>object</th>\n",
       "      <th>original_response</th>\n",
       "      <th>cleaned_response</th>\n",
       "      <th>C0</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>...</th>\n",
       "      <th>C54</th>\n",
       "      <th>C55</th>\n",
       "      <th>C56</th>\n",
       "      <th>C57</th>\n",
       "      <th>C58</th>\n",
       "      <th>C59</th>\n",
       "      <th>C60</th>\n",
       "      <th>C61</th>\n",
       "      <th>C62</th>\n",
       "      <th>C63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>10063.0</td>\n",
       "      <td>648</td>\n",
       "      <td>brick</td>\n",
       "      <td>aambeeld</td>\n",
       "      <td>aambeeld</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>5801.0</td>\n",
       "      <td>363</td>\n",
       "      <td>brick</td>\n",
       "      <td>het aanleggen van een weg</td>\n",
       "      <td>aanleggen weg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>237</td>\n",
       "      <td>brick</td>\n",
       "      <td>aannemen</td>\n",
       "      <td>aannemen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>5226.0</td>\n",
       "      <td>300</td>\n",
       "      <td>brick</td>\n",
       "      <td>aannemer</td>\n",
       "      <td>aannemer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>8321.0</td>\n",
       "      <td>555</td>\n",
       "      <td>brick</td>\n",
       "      <td>aarde</td>\n",
       "      <td>aarde</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  research_id  response_id  respondent_id object          original_response  \\\n",
       "0   CES201610      10063.0            648  brick                   aambeeld   \n",
       "1   CES201610       5801.0            363  brick  het aanleggen van een weg   \n",
       "2   CES201610       3973.0            237  brick                   aannemen   \n",
       "3   CES201610       5226.0            300  brick                   aannemer   \n",
       "4   CES201610       8321.0            555  brick                      aarde   \n",
       "\n",
       "  cleaned_response  C0  C1  C2  C3  ...  C54  C55  C56  C57  C58  C59  C60  \\\n",
       "0         aambeeld   0   0   0   0  ...    0    0    0    0    0    0    0   \n",
       "1    aanleggen weg   0   1   1   0  ...    0    0    0    0    0    0    0   \n",
       "2         aannemen   0   0   0   0  ...    0    0    0    0    0    0    0   \n",
       "3         aannemer   0   0   0   0  ...    0    0    1    0    0    0    0   \n",
       "4            aarde   1   0   0   0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "   C61  C62  C63  \n",
       "0    0    0    0  \n",
       "1    0    0    0  \n",
       "2    0    0    0  \n",
       "3    0    0    0  \n",
       "4    0    0    0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/kinaida/Documents/Capstone_Data/Crea-OFT/FleurThesis/CreateData/RequiredData/aut_categorizedRaters.csv\", encoding = 'latin-1')\n",
    "\n",
    "#data = data.drop([\"research_id\", \"response_id\", \"respondent_id\", \"object\"], axis = 1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_resp = data[['original_response']].to_numpy()\n",
    "\n",
    "embeddings = USE_module(orig_resp)\n",
    "#CNN_embeddings = USE_CNN_module(orig_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>object</th>\n",
       "      <th>original_response</th>\n",
       "      <th>cleaned_response</th>\n",
       "      <th>USE_embeddings</th>\n",
       "      <th>C0</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>...</th>\n",
       "      <th>C54</th>\n",
       "      <th>C55</th>\n",
       "      <th>C56</th>\n",
       "      <th>C57</th>\n",
       "      <th>C58</th>\n",
       "      <th>C59</th>\n",
       "      <th>C60</th>\n",
       "      <th>C61</th>\n",
       "      <th>C62</th>\n",
       "      <th>C63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>10063.0</td>\n",
       "      <td>648</td>\n",
       "      <td>brick</td>\n",
       "      <td>aambeeld</td>\n",
       "      <td>aambeeld</td>\n",
       "      <td>(tf.Tensor(-0.0033594358, shape=(), dtype=floa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>5801.0</td>\n",
       "      <td>363</td>\n",
       "      <td>brick</td>\n",
       "      <td>het aanleggen van een weg</td>\n",
       "      <td>aanleggen weg</td>\n",
       "      <td>(tf.Tensor(-0.042379927, shape=(), dtype=float...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>237</td>\n",
       "      <td>brick</td>\n",
       "      <td>aannemen</td>\n",
       "      <td>aannemen</td>\n",
       "      <td>(tf.Tensor(-0.049748804, shape=(), dtype=float...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>5226.0</td>\n",
       "      <td>300</td>\n",
       "      <td>brick</td>\n",
       "      <td>aannemer</td>\n",
       "      <td>aannemer</td>\n",
       "      <td>(tf.Tensor(-0.035619646, shape=(), dtype=float...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CES201610</td>\n",
       "      <td>8321.0</td>\n",
       "      <td>555</td>\n",
       "      <td>brick</td>\n",
       "      <td>aarde</td>\n",
       "      <td>aarde</td>\n",
       "      <td>(tf.Tensor(-0.0018415087, shape=(), dtype=floa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  research_id  response_id  respondent_id object          original_response  \\\n",
       "0   CES201610      10063.0            648  brick                   aambeeld   \n",
       "1   CES201610       5801.0            363  brick  het aanleggen van een weg   \n",
       "2   CES201610       3973.0            237  brick                   aannemen   \n",
       "3   CES201610       5226.0            300  brick                   aannemer   \n",
       "4   CES201610       8321.0            555  brick                      aarde   \n",
       "\n",
       "  cleaned_response                                     USE_embeddings  C0  C1  \\\n",
       "0         aambeeld  (tf.Tensor(-0.0033594358, shape=(), dtype=floa...   0   0   \n",
       "1    aanleggen weg  (tf.Tensor(-0.042379927, shape=(), dtype=float...   0   1   \n",
       "2         aannemen  (tf.Tensor(-0.049748804, shape=(), dtype=float...   0   0   \n",
       "3         aannemer  (tf.Tensor(-0.035619646, shape=(), dtype=float...   0   0   \n",
       "4            aarde  (tf.Tensor(-0.0018415087, shape=(), dtype=floa...   1   0   \n",
       "\n",
       "   C2  ...  C54  C55  C56  C57  C58  C59  C60  C61  C62  C63  \n",
       "0   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1   1  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "3   0  ...    0    0    1    0    0    0    0    0    0    0  \n",
       "4   0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.insert(6, \"USE_embeddings\", embeddings)\n",
    "#data.insert(7, \"USE_CNN_embeddings\", CNN_embeddings)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f90242dd550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_cols = data.loc[:, 'C0':'C63']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(numeric_cols.corr(), cmap='YlOrRd', fmt='.2f', vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.columns = [\"Original_response\", \"Cleaned_response\",\"Overig\",\"Bouwen\",\"Gooien\",\"Vandalisme\",\"Agressie\",\"Meubels\",\"Huis_Accessoires\",\"Tekenen/ Schrijven\",\"Kleding\",\"Voedsel\",\"Cosmetica_Accessoire\",\n",
    "#\"Gereedschap\",\"Technologie\",\"Component\",\"Muziekinstrument/ Geluid_maken\",\"Voertuig\",\"Item_met_emotionele_waarde\",\"Kunst\",\"Verkeer\",\n",
    "#\"Game\",\"Steunen\",\"Blokkeren\",\"Territorium_markeren\",\"Kapotslaan/ Breken\",\"Snijden\",\"Opvullen\",\"Als gewicht\",\"Bescherming\",\"Verhoging\",\n",
    "#\"Sporten\",\"Therapie\",\"Plagen\",\"Hitte/Vuur\",\"Ergens_instoppen\",\"Fantasie\",\"Schoonmaken\",\"Ruilen/geld\",\"Wetenschap\",\"In_de_keuken\",\"Accessoire_voor_tuin\",\n",
    "#\"Bedekken/Afsluiten\",\"Accessoire voor dier\",\"Feestdagen\",\"Verjaardagen\",\"Graven\",\"Moord\",\"Overleven\",\"Balanceren\",\"Versieren\",\"Beeldhouwen\",\n",
    "#\"Wapen\",\"Speelgoed\",\"Sociale_interactie\",\"Hulpmiddel\",\"Sfeer\",\"Pletten\",\"Baan/Werk\",\"Kleur\",\"Vermalen\",\"Knutselen\",\"Vermaak\", \"Natuur\",\n",
    "#\"Testen\",\"Water_tool\", \"USE_embeddings\"]\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hypermodel import HyperModel\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings.numpy()\n",
    "Y = data.iloc[:,7:71].to_numpy()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "sm = int()\n",
    "mn = int()\n",
    "\n",
    "def row_sum(predictions, test):\n",
    "    sm = statistics.mean((predictions * test).sum(axis = 1) / test.sum(axis = 1))\n",
    "    return sm\n",
    "    \n",
    "def row_mean(predictions, test):\n",
    "    mn = statistics.mean((predictions == test).mean(axis = 1))\n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 4, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 800, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 800, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape = (512, )))\n",
    "    # Tune the number of units looping over 2 till 6 Dense layers\n",
    "    # Choose an optimal value for every layer between 32-800\n",
    "    for i in range(hp.Int('num_layers', 2, 4)):\n",
    "        model.add(layers.Dense(units = hp.Int('units_' + str(i),\n",
    "                                            min_value = 32,\n",
    "                                            max_value = 800,\n",
    "                                            step = 32),\n",
    "                               activation = 'relu'))\n",
    "    # Add final output layer with sigmoid activation\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation = 'sigmoid'))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics = ['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initiate the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_categorical_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial = 3,\n",
    "    directory = '/Users/kinaida/Documents/Capstone_Data/MLC',\n",
    "    project_name = 'multi-label-classification')\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 03m 36s]\n",
      "val_categorical_accuracy: 0.7099999984105428\n",
      "\n",
      "Best val_categorical_accuracy So Far: 0.7127777536710104\n",
      "Total elapsed time: 00h 29m 11s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Search for best model\n",
    "tuner.search(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of layers is 2. The optimal number\n",
      "of units in the first densely-connected layer is 704. The optimal number\n",
      "of units in the second densely-connected layer is 32. The optimal number\n",
      "of units in the third densely-connected layer is 800 Final, the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n",
      "Results summary\n",
      "Results in /Users/kinaida/Documents/Capstone_Data/MLC/multi-label-classification\n",
      "Showing 1 best trials\n",
      "Objective(name='val_categorical_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 800\n",
      "units_1: 704\n",
      "learning_rate: 0.001\n",
      "units_2: 32\n",
      "units_3: 800\n",
      "Score: 0.7127777536710104\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of layers is {best_hps.get('num_layers')}. The optimal number\n",
    "of units in the first densely-connected layer is {best_hps.get('units_1')}. The optimal number\n",
    "of units in the second densely-connected layer is {best_hps.get('units_2')}. The optimal number\n",
    "of units in the third densely-connected layer is {best_hps.get('units_3')} Final, the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "print(tuner.results_summary(num_trials = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - 2s 14ms/step - loss: 0.1377 - categorical_accuracy: 0.2819 - val_loss: 0.0704 - val_categorical_accuracy: 0.4533\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0591 - categorical_accuracy: 0.5130 - val_loss: 0.0508 - val_categorical_accuracy: 0.5700\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0458 - categorical_accuracy: 0.6026 - val_loss: 0.0441 - val_categorical_accuracy: 0.6133\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0397 - categorical_accuracy: 0.6370 - val_loss: 0.0416 - val_categorical_accuracy: 0.6167\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0358 - categorical_accuracy: 0.6707 - val_loss: 0.0385 - val_categorical_accuracy: 0.6417\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0325 - categorical_accuracy: 0.6950 - val_loss: 0.0373 - val_categorical_accuracy: 0.6783\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0298 - categorical_accuracy: 0.7107 - val_loss: 0.0361 - val_categorical_accuracy: 0.6833\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0277 - categorical_accuracy: 0.7335 - val_loss: 0.0353 - val_categorical_accuracy: 0.6833\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0257 - categorical_accuracy: 0.7517 - val_loss: 0.0350 - val_categorical_accuracy: 0.6917\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0239 - categorical_accuracy: 0.7676 - val_loss: 0.0357 - val_categorical_accuracy: 0.6967\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0223 - categorical_accuracy: 0.7735 - val_loss: 0.0342 - val_categorical_accuracy: 0.6983\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0208 - categorical_accuracy: 0.7824 - val_loss: 0.0348 - val_categorical_accuracy: 0.6967\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0193 - categorical_accuracy: 0.7894 - val_loss: 0.0353 - val_categorical_accuracy: 0.6933\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0180 - categorical_accuracy: 0.8004 - val_loss: 0.0353 - val_categorical_accuracy: 0.6950\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0167 - categorical_accuracy: 0.8026 - val_loss: 0.0355 - val_categorical_accuracy: 0.7050\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0156 - categorical_accuracy: 0.8128 - val_loss: 0.0364 - val_categorical_accuracy: 0.6867\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0147 - categorical_accuracy: 0.8194 - val_loss: 0.0359 - val_categorical_accuracy: 0.7033\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0134 - categorical_accuracy: 0.8285 - val_loss: 0.0373 - val_categorical_accuracy: 0.6983\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0126 - categorical_accuracy: 0.8298 - val_loss: 0.0380 - val_categorical_accuracy: 0.7050\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 1s 15ms/step - loss: 0.0119 - categorical_accuracy: 0.8380 - val_loss: 0.0379 - val_categorical_accuracy: 0.6933\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0111 - categorical_accuracy: 0.8378 - val_loss: 0.0400 - val_categorical_accuracy: 0.7067\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0105 - categorical_accuracy: 0.8387 - val_loss: 0.0393 - val_categorical_accuracy: 0.7133\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0098 - categorical_accuracy: 0.8457 - val_loss: 0.0403 - val_categorical_accuracy: 0.7150\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0095 - categorical_accuracy: 0.8469 - val_loss: 0.0417 - val_categorical_accuracy: 0.6867\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0091 - categorical_accuracy: 0.8478 - val_loss: 0.0412 - val_categorical_accuracy: 0.7033\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0087 - categorical_accuracy: 0.8528 - val_loss: 0.0422 - val_categorical_accuracy: 0.6967\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0089 - categorical_accuracy: 0.8465 - val_loss: 0.0437 - val_categorical_accuracy: 0.6883\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0080 - categorical_accuracy: 0.8489 - val_loss: 0.0440 - val_categorical_accuracy: 0.6950\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0078 - categorical_accuracy: 0.8474 - val_loss: 0.0435 - val_categorical_accuracy: 0.6950\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0077 - categorical_accuracy: 0.8489 - val_loss: 0.0453 - val_categorical_accuracy: 0.6867\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0075 - categorical_accuracy: 0.8524 - val_loss: 0.0447 - val_categorical_accuracy: 0.6683\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0072 - categorical_accuracy: 0.8511 - val_loss: 0.0460 - val_categorical_accuracy: 0.6917\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0072 - categorical_accuracy: 0.8520 - val_loss: 0.0465 - val_categorical_accuracy: 0.6767\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0071 - categorical_accuracy: 0.8469 - val_loss: 0.0463 - val_categorical_accuracy: 0.6983\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0068 - categorical_accuracy: 0.8491 - val_loss: 0.0497 - val_categorical_accuracy: 0.6867\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0069 - categorical_accuracy: 0.8526 - val_loss: 0.0493 - val_categorical_accuracy: 0.6900\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0067 - categorical_accuracy: 0.8522 - val_loss: 0.0480 - val_categorical_accuracy: 0.6900\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0066 - categorical_accuracy: 0.8533 - val_loss: 0.0482 - val_categorical_accuracy: 0.6983\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0065 - categorical_accuracy: 0.8448 - val_loss: 0.0492 - val_categorical_accuracy: 0.6833\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0065 - categorical_accuracy: 0.8519 - val_loss: 0.0489 - val_categorical_accuracy: 0.6967\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0066 - categorical_accuracy: 0.8472 - val_loss: 0.0480 - val_categorical_accuracy: 0.7017\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0063 - categorical_accuracy: 0.8535 - val_loss: 0.0487 - val_categorical_accuracy: 0.6933\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0062 - categorical_accuracy: 0.8504 - val_loss: 0.0496 - val_categorical_accuracy: 0.6917\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0060 - categorical_accuracy: 0.8528 - val_loss: 0.0505 - val_categorical_accuracy: 0.6833\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0060 - categorical_accuracy: 0.8474 - val_loss: 0.0500 - val_categorical_accuracy: 0.6817\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0059 - categorical_accuracy: 0.8485 - val_loss: 0.0506 - val_categorical_accuracy: 0.6900\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0061 - categorical_accuracy: 0.8506 - val_loss: 0.0518 - val_categorical_accuracy: 0.7100\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0062 - categorical_accuracy: 0.8456 - val_loss: 0.0509 - val_categorical_accuracy: 0.6767\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0059 - categorical_accuracy: 0.8515 - val_loss: 0.0520 - val_categorical_accuracy: 0.6933\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0060 - categorical_accuracy: 0.8500 - val_loss: 0.0522 - val_categorical_accuracy: 0.6967\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 1s 10ms/step - loss: 0.0059 - categorical_accuracy: 0.8446 - val_loss: 0.0506 - val_categorical_accuracy: 0.6800\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0056 - categorical_accuracy: 0.8500 - val_loss: 0.0515 - val_categorical_accuracy: 0.6900\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0059 - categorical_accuracy: 0.8472 - val_loss: 0.0528 - val_categorical_accuracy: 0.7000\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0058 - categorical_accuracy: 0.8487 - val_loss: 0.0524 - val_categorical_accuracy: 0.6850\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0056 - categorical_accuracy: 0.8548 - val_loss: 0.0520 - val_categorical_accuracy: 0.6950\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8454 - val_loss: 0.0529 - val_categorical_accuracy: 0.6850\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0055 - categorical_accuracy: 0.8567 - val_loss: 0.0538 - val_categorical_accuracy: 0.6983\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0057 - categorical_accuracy: 0.8491 - val_loss: 0.0516 - val_categorical_accuracy: 0.6850\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0056 - categorical_accuracy: 0.8515 - val_loss: 0.0549 - val_categorical_accuracy: 0.6783\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0058 - categorical_accuracy: 0.8496 - val_loss: 0.0525 - val_categorical_accuracy: 0.7050\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0054 - categorical_accuracy: 0.8498 - val_loss: 0.0540 - val_categorical_accuracy: 0.6917\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0055 - categorical_accuracy: 0.8537 - val_loss: 0.0542 - val_categorical_accuracy: 0.6917\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0055 - categorical_accuracy: 0.8504 - val_loss: 0.0544 - val_categorical_accuracy: 0.7017\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0054 - categorical_accuracy: 0.8469 - val_loss: 0.0556 - val_categorical_accuracy: 0.6917\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0056 - categorical_accuracy: 0.8515 - val_loss: 0.0527 - val_categorical_accuracy: 0.6817\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0055 - categorical_accuracy: 0.8476 - val_loss: 0.0546 - val_categorical_accuracy: 0.7017\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0054 - categorical_accuracy: 0.8572 - val_loss: 0.0553 - val_categorical_accuracy: 0.6950\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0054 - categorical_accuracy: 0.8511 - val_loss: 0.0551 - val_categorical_accuracy: 0.7117\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0055 - categorical_accuracy: 0.8509 - val_loss: 0.0544 - val_categorical_accuracy: 0.6883\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8485 - val_loss: 0.0558 - val_categorical_accuracy: 0.6950\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8517 - val_loss: 0.0545 - val_categorical_accuracy: 0.6817\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0052 - categorical_accuracy: 0.8522 - val_loss: 0.0560 - val_categorical_accuracy: 0.6900\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8504 - val_loss: 0.0563 - val_categorical_accuracy: 0.7033\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8500 - val_loss: 0.0564 - val_categorical_accuracy: 0.6867\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0052 - categorical_accuracy: 0.8526 - val_loss: 0.0558 - val_categorical_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0051 - categorical_accuracy: 0.8509 - val_loss: 0.0562 - val_categorical_accuracy: 0.6900\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8515 - val_loss: 0.0553 - val_categorical_accuracy: 0.7067\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0053 - categorical_accuracy: 0.8467 - val_loss: 0.0574 - val_categorical_accuracy: 0.6950\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0052 - categorical_accuracy: 0.8544 - val_loss: 0.0541 - val_categorical_accuracy: 0.7117\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0052 - categorical_accuracy: 0.8459 - val_loss: 0.0570 - val_categorical_accuracy: 0.6883\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0051 - categorical_accuracy: 0.8506 - val_loss: 0.0555 - val_categorical_accuracy: 0.6900\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0052 - categorical_accuracy: 0.8496 - val_loss: 0.0579 - val_categorical_accuracy: 0.7000\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0050 - categorical_accuracy: 0.8467 - val_loss: 0.0563 - val_categorical_accuracy: 0.6900\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0051 - categorical_accuracy: 0.8483 - val_loss: 0.0563 - val_categorical_accuracy: 0.7117\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0051 - categorical_accuracy: 0.8522 - val_loss: 0.0541 - val_categorical_accuracy: 0.7117\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0049 - categorical_accuracy: 0.8522 - val_loss: 0.0584 - val_categorical_accuracy: 0.7100\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0051 - categorical_accuracy: 0.8509 - val_loss: 0.0577 - val_categorical_accuracy: 0.6983\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0050 - categorical_accuracy: 0.8546 - val_loss: 0.0569 - val_categorical_accuracy: 0.7033\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0050 - categorical_accuracy: 0.8511 - val_loss: 0.0581 - val_categorical_accuracy: 0.6933\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0049 - categorical_accuracy: 0.8513 - val_loss: 0.0573 - val_categorical_accuracy: 0.7083\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0048 - categorical_accuracy: 0.8517 - val_loss: 0.0579 - val_categorical_accuracy: 0.7133\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0049 - categorical_accuracy: 0.8526 - val_loss: 0.0583 - val_categorical_accuracy: 0.7067\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0049 - categorical_accuracy: 0.8520 - val_loss: 0.0595 - val_categorical_accuracy: 0.7000\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0051 - categorical_accuracy: 0.8506 - val_loss: 0.0573 - val_categorical_accuracy: 0.6967\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0048 - categorical_accuracy: 0.8472 - val_loss: 0.0590 - val_categorical_accuracy: 0.7033\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0047 - categorical_accuracy: 0.8531 - val_loss: 0.0573 - val_categorical_accuracy: 0.7000\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0049 - categorical_accuracy: 0.8537 - val_loss: 0.0587 - val_categorical_accuracy: 0.7017\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0048 - categorical_accuracy: 0.8465 - val_loss: 0.0589 - val_categorical_accuracy: 0.6817\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 11ms/step - loss: 0.0048 - categorical_accuracy: 0.8496 - val_loss: 0.0588 - val_categorical_accuracy: 0.7000\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 1s 14ms/step - loss: 0.0047 - categorical_accuracy: 0.8478 - val_loss: 0.0575 - val_categorical_accuracy: 0.6883\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model   = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), \n",
    "                    epochs = 100, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Threshold: 0.1\n",
      "Precision: 0.6877, Recall: 0.7812, F1-measure: 0.7315, Hamming loss: 0.0121, Sum Metric: 0.8051, Mean Metric: 0.9879\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.2\n",
      "Precision: 0.7190, Recall: 0.7528, F1-measure: 0.7355, Hamming loss: 0.0114, Sum Metric: 0.7797, Mean Metric: 0.9886\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.3\n",
      "Precision: 0.7392, Recall: 0.7219, F1-measure: 0.7305, Hamming loss: 0.0112, Sum Metric: 0.7542, Mean Metric: 0.9888\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.4\n",
      "Precision: 0.7633, Recall: 0.6934, F1-measure: 0.7267, Hamming loss: 0.0110, Sum Metric: 0.7289, Mean Metric: 0.9890\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.5\n",
      "Precision: 0.7803, Recall: 0.6675, F1-measure: 0.7195, Hamming loss: 0.0110, Sum Metric: 0.7083, Mean Metric: 0.9890\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.6\n",
      "Precision: 0.7960, Recall: 0.6465, F1-measure: 0.7135, Hamming loss: 0.0109, Sum Metric: 0.6919, Mean Metric: 0.9891\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.7\n",
      "Precision: 0.8254, Recall: 0.6193, F1-measure: 0.7076, Hamming loss: 0.0108, Sum Metric: 0.6699, Mean Metric: 0.9892\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.8\n",
      "Precision: 0.8534, Recall: 0.5970, F1-measure: 0.7025, Hamming loss: 0.0107, Sum Metric: 0.6515, Mean Metric: 0.9893\n",
      "Micro-average quality numbers\n",
      "Threshold: 0.9\n",
      "Precision: 0.8774, Recall: 0.5661, F1-measure: 0.6882, Hamming loss: 0.0108, Sum Metric: 0.6240, Mean Metric: 0.9892\n"
     ]
    }
   ],
   "source": [
    "# now we can test the accuracy of the model on the test data\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# make model predictions\n",
    "Y_pred         = model.predict(X_test)\n",
    "thresholds     = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for val in thresholds:\n",
    "    predictions       = Y_pred.copy()\n",
    "  \n",
    "    predictions[predictions >= val] = 1\n",
    "    predictions[predictions < val]  = 0\n",
    "\n",
    "    precision   = precision_score(Y_test, predictions, average = 'micro')\n",
    "    recall      = recall_score(Y_test, predictions, average = 'micro')\n",
    "    f1          = f1_score(Y_test, predictions, average = 'micro')\n",
    "    hamming     = hamming_loss(Y_test, predictions)\n",
    "    sum_metric  = row_sum(predictions, Y_test)\n",
    "    mean_metric = row_mean(predictions, Y_test)\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Threshold: {:.1f}\".format(val))\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}, Hamming loss: {:.4f}, Sum Metric: {:.4f}, Mean Metric: {:.4f}\".format(precision, \n",
    "                                                                                               recall, f1, hamming, sum_metric, mean_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent variables\n",
    "Y = data.iloc[:, 7:71]\n",
    "\n",
    "# Independent variables\n",
    "X = embeddings.numpy()\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "# corresponding responses to test set\n",
    "corr_response = data.iloc[Y_test.index, 5].reset_index(drop = True)\n",
    "co_response   = data.iloc[Y_test.index, 5]\n",
    "\n",
    "# create a dataframe for the predictions by the neural network\n",
    "df = pd.DataFrame(data = Y_pred[0:,0:],\n",
    "                  index = [i for i in range(Y_pred.shape[0])],\n",
    "                  columns = ['C' + str(i) for i in range(Y_pred.shape[1])])\n",
    "\n",
    "pred_data = pd.concat([corr_response, df], axis = 1)\n",
    "true_data = pd.concat([co_response, Y_test], axis = 1).reset_index(drop = True)\n",
    "\n",
    "# Write to csv files\n",
    "pred_data.to_csv('algorithm_predictions.csv')\n",
    "true_data.to_csv('true_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data_rater1.csv' does not exist: b'data_rater1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3331d5ebfb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load all raters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrater01\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_rater1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrater02\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_rater2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrater03\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_rater3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data_rater1.csv' does not exist: b'data_rater1.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# Load all raters\n",
    "rater01      = pd.read_csv(\"data_rater1.csv\", encoding = 'latin-1')\n",
    "rater02      = pd.read_csv(\"data_rater2.csv\", encoding = 'latin-1')\n",
    "rater03      = pd.read_csv(\"data_rater3.csv\", encoding = 'latin-1')\n",
    "\n",
    "# Rater 1 vs Rater 2\n",
    "rater01_02   = hamming_loss(rater01.iloc[:, 6:71], rater02.iloc[:, 6:71])\n",
    "precision1   = precision_score(rater01.iloc[:, 6:71], rater02.iloc[:, 6:71], average = 'micro')\n",
    "recall1      = recall_score(rater01.iloc[:, 6:71], rater02.iloc[:, 6:71], average = 'micro')\n",
    "f11          = f1_score(rater01.iloc[:, 6:71], rater02.iloc[:, 6:71], average = 'micro')\n",
    "sum_metric1  = row_sum(rater01.iloc[:, 6:71], rater02.iloc[:, 6:71])\n",
    "mean_metric1 = row_mean(rater01.iloc[:, 6:71], rater02.iloc[:, 6:71])\n",
    "\n",
    "# Rater 1 vs Rater 3\n",
    "rater01_03   = hamming_loss(rater01.iloc[:, 6:71], rater03.iloc[:, 6:71])\n",
    "precision2   = precision_score(rater01.iloc[:, 6:71], rater03.iloc[:, 6:71], average = 'micro')\n",
    "recall2      = recall_score(rater01.iloc[:, 6:71], rater03.iloc[:, 6:71], average = 'micro')\n",
    "f12          = f1_score(rater01.iloc[:, 6:71], rater03.iloc[:, 6:71], average = 'micro')\n",
    "sum_metric2  = row_sum(rater01.iloc[:, 6:71], rater03.iloc[:, 6:71])\n",
    "mean_metric2 = row_mean(rater01.iloc[:, 6:71], rater03.iloc[:, 6:71])\n",
    "\n",
    "# Rater 2 vs Rater 3\n",
    "rater02_03   = hamming_loss(rater02.iloc[:, 6:71], rater03.iloc[:, 6:71])\n",
    "precision3   = precision_score(rater02.iloc[:, 6:71], rater03.iloc[:, 6:71], average = 'micro')\n",
    "recall3      = recall_score(rater02.iloc[:, 6:71], rater03.iloc[:, 6:71], average = 'micro')\n",
    "f13          = f1_score(rater02.iloc[:, 6:71], rater03.iloc[:, 6:71], average = 'micro')\n",
    "sum_metric3  = row_sum(rater02.iloc[:, 6:71], rater03.iloc[:, 6:71])\n",
    "mean_metric3 = row_mean(rater02.iloc[:, 6:71], rater03.iloc[:, 6:71])\n",
    "\n",
    "print(\"Rater 1 vs Rater 2:\")\n",
    "print(\"Hamming Loss:\", round(rater01_02, 3))\n",
    "print(\"Precision:\", round(precision1, 3))\n",
    "print(\"Recall:\", round(recall1, 3))\n",
    "print(\"F-1:\", round(f11, 3))\n",
    "print(\"Sum Metric:\", round(sum_metric1, 3))\n",
    "print(\"Mean Metric:\", round(mean_metric1, 3))\n",
    "\n",
    "print(\"Rater 1 vs Rater 3:\")\n",
    "print(\"Hamming Loss:\", round(rater01_03, 3))\n",
    "print(\"Precision:\", round(precision2, 3))\n",
    "print(\"Recall:\", round(recall2, 3))\n",
    "print(\"F-1:\", round(f12, 3))\n",
    "print(\"Sum Metric:\", round(sum_metric2, 3))\n",
    "print(\"Mean Metric:\", round(mean_metric2, 3))\n",
    "\n",
    "print(\"Rater 2 vs Rater 3:\")\n",
    "print(\"Hamming Loss:\", round(rater02_03, 3))\n",
    "print(\"Precision:\", round(precision3, 3))\n",
    "print(\"Recall:\", round(recall3, 3))\n",
    "print(\"F-1:\", round(f13, 3))\n",
    "print(\"Sum Metric:\", round(sum_metric3, 3))\n",
    "print(\"Mean Metric:\", round(mean_metric3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select same rows for the raters as for the test data from the algorithm\n",
    "rat01_alg    = rater01.iloc[y_test.index, 6:71]\n",
    "rat02_alg    = rater02.iloc[y_test.index, 6:71]\n",
    "rat03_alg    = rater03.iloc[y_test.index, 6:71]\n",
    "\n",
    "# Rater 1 vs Algorithm\n",
    "rater01_test = hamming_loss(rat01_alg, y_test)\n",
    "\n",
    "# Rater 1 vs Algorithm\n",
    "rater02_test = hamming_loss(rat02_alg, y_test)\n",
    "\n",
    "# Rater 2 vs Algorithm\n",
    "rater03_test = hamming_loss(rat03_alg, y_test)\n",
    "\n",
    "print(\"Rater 1 vs Algorithm:\", rater01_test)\n",
    "print(\"Rater 2 vs Algorithm:\", rater02_test)\n",
    "print(\"Rater 3 vs Algorithm:\", rater03_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
